<html>
<head>
    <title>Eugene Bagdasaryan's website</title>
    <!--Import Google Icon Font-->
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

    <!-- Compiled and minified CSS -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.min.css">
    <!--Let browser know website is optimized for mobile-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <link rel="shortcut icon" type="image/png" href="assets/images/favicon.ico"/>

</head>
<body>

<div class="container">

    <div class="row">
        <div class="row center-align">
            <div class="push-s1 col s10 m4 l3 ">
                <img src="assets/images/zhenya_new.jpg" style="height: 150px;margin-top: 30px;"/>
            </div>

            <div class="col push-s1 s10 m6 l6">
                <div class="row center-align">
                    <h3>Eugene Bagdasaryan</h3>
                </div>
                <div class="divider"></div>
                <div class="row center-align">
                    <div class="col s6 m3" style="padding-bottom: 20px;">
                        <a href="mailto:eugene@cs.cornell.edu" class="lighten-1 waves-effect waves-teal btn-flat">Email</a>
                    </div>
                    <div class="col s6 m3" style="padding-bottom: 20px;">
                        <a href="https://twitter.com/ebagdasa" class="lighten-1 waves-effect waves-teal btn-flat">Twitter</a>
                    </div>
                    <div class="col s6 m3" style="padding-bottom: 20px;">
                        <a href="https://scholar.google.com/citations?user=_MfoOC8AAAAJ&hl=en" class="lighten-1 waves-effect waves-teal btn-flat">
                            Scholar
                            <!--<img src="assets/images/gs.png" style="height: 20px">-->
                        </a>

                    </div>
                    <div class="col s6 m3" style="padding-bottom: 20px;">
                        <a href="assets/files/EvgenyBagdasaryanResumeSpring2020.pdf" class="lighten-1 waves-effect waves-teal btn-flat">
                            <!--<i class="material-icons">description</i> -->
                            Resume
                        </a>
                    </div>
                </div>

            </div>
        </div>
        <div class="divider"></div>
        <div class="col push-s1 s10 m6 l6">

            <div class="section">
                <h5>Bio</h5>
                <p style="text-align: justify; text-justify: inter-word;">
                    I am a CS PhD candidate at Cornell Tech working on privacy and security
                    in context of machine learning systems.
                    I am co-advised by Professors  <a href="https://destrin.smalldata.io/">Deborah Estrin</a> 
                    and  <a href="https://www.cs.cornell.edu/~shmat/">Vitaly Shmatikov</a>.
                </p>
                <p style="text-align: justify; text-justify: inter-word;">
                    Specifically, my work focuses on
                    federated learning, differential privacy, and backdoor attacks in ML
                    (<a href="https://arxiv.org/abs/1905.12101">NeurIPS'19</a>, <a href="https://arxiv.org/abs/1807.00459">AISTATS'20</a>). 
                    My other interests include
                    <a href="https://ancile-project.github.io/">Ancile Project</a>,
                    which introduces language-level control for data usage (<a href="assets/files/ancile.pdf">WPES'19</a>)
                    and <a href="https://openrec.ai">OpenRec project</a> which proposes modular design for deep learning recommender systems.
                    Before joining Cornell I worked at Cisco developing and open sourcing code for OpenStack cloud infrastructure.
                    And during recent internships I worked on Amazon Alexa and Google FL platforms.
                </p>
                
                <p>Happy to collaborate or just chat on these topics, send me an email. </p>
            </div>
        </div>

        <div class="col push-s1 s10 m5 l5 push-l1 push-m1">
            <div class="section">
                <h5>Recent news</h5>
                <ul class="collection">
                    <li class="collection-item">
                        <b>Jun 2020</b>, Ancile project was discussed in <a href="https://news.cornell.edu/stories/2020/06/platform-empowers-users-control-their-personal-data">Cornell Chronicle</a>.
                    </li>
                    <li class="collection-item">
                        <b>Jan 2020</b>, Our backdoor federated learning <a href="https://arxiv.org/abs/1807.00459">paper</a> was accepted to AISTATS'20!
                    </li>
                    <li class="collection-item">
                        <b>Nov 2019</b>, Became a PhD Candidate. Title: "Evaluating privacy preserving techniques in machine learning".
                    </li>
                    <li class="collection-item">
                        <b>Sep 2019</b>, Our <a href="https://arxiv.org/abs/1905.12101">paper</a> that discovers impact of
                        Differential Privacy on model Fairness was accepted to NeurIPS'19.
                    </li>
                    <!--<li class="collection-item">-->
                        <!--<b>Aug 2019</b>, Our work on <a href="assets/files/ancile.pdf">Ancile</a> use-based privacy-->
                         <!--system was accepted to WPES'19.-->
                    <!--</li>-->
<!--                    <li class="collection-item">-->
<!--                        <b>Aug 2019</b>, Presented at <a href="http://privaci.info/ci_symposium.html">Contextual Integrity Symposium</a>-->
<!--                        on Contextual Recommendation Sharing.-->
<!--                    </li>-->
                    <li class="collection-item">
                        <b>June 2019</b>, <a href="https://www.dli.tech.cornell.edu/doctoralfellows">Digital Life Initiative</a> fellow 2019-2020.
                    </li>
                </ul>

            </div>
        </div>
        <div class="col push-s1 s10 m12 l12">
            <div class="divider"></div>
            <div class="section">
                <h5>Research papers</h5>
                <ul class="collapsible" data-collapsible="accordion">
                    <li>
                        <div class="collapsible-header"><i class="material-icons">visibility_off</i>Blind Backdoors in Deep Learning Models</div>
                        <div class="collapsible-body">
                            <p>We propose a novel attack that injects complex and semantic backdoors without access to the training data or the model and evades all known
                                defenses.</p>
                            <span><a href="https://arxiv.org/abs/2005.03823" class="collection-item">[Paper]</a>
                            </span>
                        </div>
                    </li>
                    <li>
                        <div class="collapsible-header"><i class="material-icons">smartphone</i>How To Backdoor Federated Learning</div>
                        <div class="collapsible-body">
                            <p>We introduce a constrain-and-scale attack,
                                a form of data poisoning, that can stealthily inject a backdoor into one of the participating models
                                during a single round of Federated Learning training.
                                This attack can avoid proposed defenses and propagate the backdoor to a global server
                                that will distribute the compromised model to other participants.</p>
                            <a href="https://arxiv.org/abs/1807.00459" class="collection-item">[AISTATS, 2020]</a>,
                            <a href="https://github.com/ebagdasa/backdoor_federated_learning" class="collection-item">
                                [Code]</a>
                        </div>
                    </li>

                    <li>
                        <div class="collapsible-header"><i class="material-icons">local_hospital</i>Salvaging Federated Learning by Local Adaptation</div>
                        <div class="collapsible-body">
                            <p>Recovering participants' performance on their data when using federated learning with robustness and privacy techniques.</p>
                            <span><a href="https://arxiv.org/abs/2002.04758" class="collection-item">[Paper]</a>, 
                                <a href="https://github.com/ebagdasa/federated_adaptation" class="collection-item">[Code]</a>,
                            </span>
                        </div>
                    </li>
                    <li>
                        <div class="collapsible-header"><i class="material-icons">done</i>Ancile: Enhancing Privacy for Ubiquitous Computing with Use-Based Privacy</div>
                        <div class="collapsible-body">
                            <p>A novel platform that enables control over application's data usage with language level policies
                                and implementing use-based privacy.</p>
                            <span><a href="assets/files/ancile.pdf" class="collection-item">[WPES'19]</a>, 
                                <a href="https://github.com/ancile-project/ancile" class="collection-item">[Code]</a>,
                                <a href="https://docs.google.com/presentation/d/1a2zkEvXLzWJ-CWu2AGl_Bc2pUwKEnnoEKyc17MZbmFQ/edit?usp=sharing" class="collection-item">[Slides]</a>.
                            </span>
                        </div>
                    </li>
                    <li>
                        <div class="collapsible-header"><i class="material-icons">face</i>Differential Privacy Has Disparate Impact on Model Accuracy</div>
                        <div class="collapsible-body">
                            <p>This project discusses a new trade off between privacy and fairness. We observe
                                that training a Machine Learning model with Differential Privacy reduces accuracy on
                                underrepresented groups.</p>
                            <span><a href="https://arxiv.org/abs/1905.12101" class="collection-item">[NeurIPS, 2019]</a>,
                            <a href="https://github.com/ebagdasa/differential-privacy-vs-fairness" class="collection-item">
                                [Code]</a>
                            </span>
                        </div>
                    </li>

                    <li>
                        <div class="collapsible-header"><i class="material-icons">extension</i>Openrec: A modular framework for extensible and adaptable recommendation algorithms</div>
                        <div class="collapsible-body">
                            <p>An open and modular Python framework that supports extensible and adaptable research in recommender systems.
                            </p>
                            <a href="https://dl.acm.org/citation.cfm?id=3159681" class="collection-item">[WSDM, 2018]</a>,
                            <a href="https://github.com/ylongqi/openrec" class="collection-item">
                                [Code]</a>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
        <!--<div class="divider"></div>-->
        <!--<div class="section">-->
        <!--<h5>Links</h5>-->
        <!--<div class="col">-->
        <!--<div><a href="https://twitter.com/ebagdasa">Twitter</a></div>-->
        <!--<div><a href="https://github.com/ebagdasa">Github</a></div>-->
        <!--<div><a href="https://scholar.google.com/citations?user=_MfoOC8AAAAJ&hl=en">Google Scholar</a></div>-->
        <!--<div><a href="assets/files/EvgenyBagdasaryanResume.pdf">Resume [Oct, 2018]</a></div>-->
        <!--</div>-->
        <!--</div>-->
    </div>

    <div class="footer-copyright right-align">Eugene Bagdasaryan, updated on May 2020.</div>
</div>


<!-- Compiled and minified JavaScript -->
<script type="text/javascript" src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
<script type="text/javascript" src="assets/js/script.js"></script>
</body>

</html>
